# 语言模型

### 什么是语言模型

![image-20230313202404923](0313.assets/image-20230313202404923.png)

### 语言模型的应用

### 语言模型的分类

![image-20230313203053786](0313.assets/image-20230313203053786.png)

![image-20230313203115603](0313.assets/image-20230313203115603.png)

### N-gram语言模型

统计的计算方式

![image-20230313203309948](0313.assets/image-20230313203309948.png)

![image-20230313203334272](0313.assets/image-20230313203334272.png)

![image-20230313203347470](0313.assets/image-20230313203347470.png)

N-gram存在问题

![image-20230313203847980](0313.assets/image-20230313203847980.png)

![image-20230313204229076](0313.assets/image-20230313204229076.png)

#### 关于语料中未出现词的预测

![image-20230313205045567](0313.assets/image-20230313205045567.png)

不能直接为没见的词分配0概率，这样会导致出现未见过词的句子概率都为0

#### 平滑方法

![image-20230313205203326](0313.assets/image-20230313205203326.png)

![image-20230313205849595](0313.assets/image-20230313205849595.png)

但是仍然无法处理d单词本身就没有出现的情况

![image-20230313210442130](0313.assets/image-20230313210442130.png)

#### UNK替换未见过的词

![image-20230313210646419](0313.assets/image-20230313210646419.png)

#### 插值

![image-20230313210756248](0313.assets/image-20230313210756248.png)

### 语言模型的评价指标

![image-20230313210953635](0313.assets/image-20230313210953635.png)

但是如果一个语言模型为所有句子的ppl打分都很低，也不能说明模型的性能好。

![image-20230313211128881](0313.assets/image-20230313211128881.png)

### 神经网络语言模型

![image-20230313211548932](0313.assets/image-20230313211548932.png)

未见过词：

神经网络语言模型可以很好的解决未见过词的情况，模型的输出是在词表维度的分类结果，也就是说词表中的每个词都会有概率值，即使这个单词在训练数据中没有出现。

长距离依赖：

如RNN的模型结构，长文本输入和短文本输入的过程是一样的，最后还需要在文本长度的维度进行平均，没有带来计算上的额外负担，参数量随着文本长度发生变化。而N-gram模型就需要额外计算很多的条件概率。

### 两类语言模型的对比

![image-20230314203354631](0313.assets/image-20230314203354631.png)

### 总结

![image-20230314204853097](0313.assets/image-20230314204853097.png)

### 预训练模型

#### 预训练思想

```
预训练是什么？
随机初始化的语言模型存在一定的缺陷，比如对于一个中文文本分类任务，随机初始化相当于完全不理解中文，先学习中文文本，再对中文文本进行分类，而预训练的做法是先对中文文本有一定的认识（掌握中文的语言规律），只需要少量的样本就可以完成分类。这种是事先不针对下游任务进行的通用训练过程称为预训练。

预训练的数据最好是不需要人工标注的，自监督学习

词向量的训练只保留了embedding的内容，而预训练的方法是embedding+模型结构

bert类模型的优点：
1.预训练的思想
2.模型结构

```



#### 预训练方式

![image-20230315210841013](0313.assets/image-20230315210841013.png)

```
双向语言模型，自编码语言模型

单向语言模型，自回归语言模型

bert的预训练任务是什么？
完形填空、下一句预测

预训练的任务还有很多种，有论文分析实际上句子关系预测并不重要，而当前更流行的预训练任务是自回归的模型，用前n个字预测下一个字，这种方式更加适合生成式任务。
最早的语言模型是采用自回归的方法，但是模型的性能不足，效果不好，而bert提出后，在23年前研究人员认为很大程度上是自编码的任务带来的。但是随着gpt的大火，自回归任务的重要性又被重新提起。效果好的才是正确的。
```



![image-20230315211537611](0313.assets/image-20230315211537611.png)

```
词向量与语言模型有什么不同？
词向量的缺陷：在不同语境下的词向量是相同的

而语言模型（词向量+模型）会根据不同的上下文产生不同的输出，原因是语言模型的生成结果会有模型参与运算（网络层的影响）的地方，就类似rnn在不同时间步的输出会考虑前一个时间步的状态

```

#### 下游任务中的使用

![image-20240226171213608](语言模型和预训练.assets/image-20240226171213608.png)





#### BERT结构

##### Encoder

输入的是文本输出的是向量，所以称它为编码器，一个encoder包含多个transform层

![image-20230315212045165](0313.assets/image-20230315212045165.png)

##### Embedding

![image-20230315213335314](0313.assets/image-20230315213335314.png)

![image-20230315213129917](0313.assets/image-20230315213129917.png)



```
bert的embedding与传统embedding有什么区别？

传统的embedding做法是将token映射成1*128的向量，一段文本就是10*128，token_embndding的过程。
而bert在这个基础上又有额外的补充：
segment embedding
position embedding
```





##### Transformer

###### self-attention

![image-20230315222033545](0313.assets/image-20230315222033545.png)

![image-20230315221205369](0313.assets/image-20230315221205369.png)

```
经过embeding层后得到一个10*768的矩阵，即x是10*768，之后x经过3个不同的线性层（Wx+b）,每个线性层的w是768*768的形状，b是768，分别得到3个形状相同的QKV，形状都是10*768，
```

多头机制

![image-20240227124704050](语言模型和预训练.assets/image-20240227124704050.png)

```
多头机制是什么？有什么好处？

对Q，K，V进行分割，把768拆开，768=256*3  ， 
10 * 768 = 10 *256 *3 
这样做的目的是把同一个权重分散到不同的子空间进行学习，最后再总结到一起，希望学习到更好的参数，相当于模型融合。模型集成的思想，内部的模型融合，相当于在同时训练多个模型。


/dk^0.5的含义及作用

降低原矩阵中实数的大小，使得经过softmax后的结果不会出现一个很大的值和其他很小接近0的值，dk设置为 768/头数
```





![image-20230315214803305](0313.assets/image-20230315214803305.png)

```
Q*K.T的含义：
每个字对这句话中其他字的相关性分数，即每个字与其他字的关系
之后再逐行对相关性分数进行softmax归一化，得到加和为1的0到1之间的值，这行代表是当前字对其他字的注意力得分

Q*K.T的优势：
RNN将每个字的信息都保存在一个特定的h中，这种做法会随着文本长度的增加出现遗忘前面文本信息的现象
而Q*K.T得到的注意力利用矩阵的做法，计算目标字与第一个字的注意力和与最后一个字的注意力是一样的，不会出现随文本长度增加导致信息丢失的现象

自注意力的self是指当前文本和自身进行的运算，attention是指当文本中不同的字与其他字之间的相关性是不同的。

文本长度*文本长度的方阵保证了文本中的每个字见到第一个字和最后一个字的概率是一样的，不会出现丢失。这是相比于LSTM模型结构的本质区别。
```







###### 残差机制

![image-20230315222107163](0313.assets/image-20230315222107163.png)

```
bert中的残差机制：

X 是模型的原始输入，Z是经过attention机制后的结果，两者相加保证了原始输入信息不会太多丢失，再经过归一化层。
防止随着网络层加深而导致原始信息的丢失
```





##### 前馈层

![image-20230315222416720](0313.assets/image-20230315222416720.png)

```
前馈层包含两个线性层，一个负责放大输入的维度，另一个再将其缩小会原来的维度，中间经过GELU激活层，再经过一个残差层把原始输入和输出结果进行相加。
```



##### 总结

![image-20230315223243984](0313.assets/image-20230315223243984.png)

###### BERT优势

![image-20230316200029197](0313.assets/image-20230316200029197.png)

###### BERT劣势

![image-20230316200120210](0313.assets/image-20230316200120210.png)

#### 预训练技术发展

##### ELMo

![image-20230316200347084](0313.assets/image-20230316200347084.png)

![image-20230316200406965](0313.assets/image-20230316200406965.png)

![image-20230316200426533](0313.assets/image-20230316200426533.png)



##### GPT

![image-20230316200527494](0313.assets/image-20230316200527494.png)

![image-20230316200555379](0313.assets/image-20230316200555379.png)

![image-20230316200610150](0313.assets/image-20230316200610150.png)

##### BERT

##### GPT2

![image-20230316200948900](0313.assets/image-20230316200948900.png)

![image-20230316201215638](0313.assets/image-20230316201215638.png)

![image-20230316201336605](0313.assets/image-20230316201336605.png)

一定程度上接近了ChatGpt的思路，prompt的前身

##### Roberta

![image-20230316201637807](0313.assets/image-20230316201637807.png)

![image-20230316201700557](0313.assets/image-20230316201700557.png)

![image-20230316201726972](0313.assets/image-20230316201726972.png)

##### ALBERT

![image-20230316201809614](0313.assets/image-20230316201809614.png)

 Embedding层的因式分解

![image-20230316202030935](0313.assets/image-20230316202030935.png)

###### 跨层参数共享

![image-20230316202051498](0313.assets/image-20230316202051498.png)

###### 重新设计预训练任务

![image-20230316202128545](0313.assets/image-20230316202128545.png)

现在看来效果也一般

###### 局限性

![image-20230316202231990](0313.assets/image-20230316202231990.png)

![image-20230316202325436](0313.assets/image-20230316202325436.png)

##### GPT3

![image-20230316202358285](0313.assets/image-20230316202358285.png)

![image-20230316202605539](0313.assets/image-20230316202605539.png)

![image-20230316202920803](0313.assets/image-20230316202920803.png)

![image-20230316203039610](0313.assets/image-20230316203039610.png)

##### Prompt

![image-20230316203106910](0313.assets/image-20230316203106910.png)

##### 总结

![image-20230316203128244](0313.assets/image-20230316203128244.png)

##### 预训练的发展方向

![image-20230316203804113](0313.assets/image-20230316203804113.png)

```
需要注意的是bert是纯encoder结构，只使用了transformer的encoder部分，还有decoder用于生成任务
```

